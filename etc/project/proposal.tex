\documentclass{article}

\usepackage[latin1]{inputenc}    
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage[toc,page]{appendix} 

\usepackage{wrapfig}
\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}

\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mdwlist}
\usepackage{booktabs} 

\usepackage{fullpage}

\begin{document}

\title{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}       
\author{Reilly Jack\and Prodhomme Boris\and Grauzam Johann\\ }       
\date{\today}         
\maketitle

\begin{abstract}

	ADMM \cite{ref1}
	
\end{abstract}

\section{Literature review}
 \label{Literature review}
 
	liyhgihgoih

\section{Different software frameworks}
 \label{Different software frameworks}

\subsection{Apache Hadoop}
	\label{Apache Hadoop}
	
	lrjfzjiozjf
	
\subsection{Mesos}
	\label{Mesos}
	
	lshfcizufhoizauh	
	
\subsection{Spark}
	\label{Spark}
	
	zdfjzpofjz


\section{Alternating Direction Method of Multipliers (ADMM)}
	\label{Alternating Direction Method of Multipliers (ADMM)}
	
\subsection{Dual Ascent}
	\label{Dual Ascent}
	
	Let consider the following convex optimization problem:
\begin{eqnarray}
\label{Dual_ascent_pb}
\underset{x}{\text{minimize}} & & f(x) \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}
with variables $x \in \mathbb{R}^n$, where $A \in \mathbb{R}^{m \times n}$ and $ f : \mathbb{R}^n \to \mathbb{R}$ is convex. 
The Lagrangian of problem \ref{Dual_ascent_pb} is:
\begin{eqnarray*}
\label{Dual_ascent_Lag}
L(x,\nu) = f(x) + \nu^T (b - Ax)
\end{eqnarray*}
and the dual function is:
\begin{eqnarray*}
g(\nu) = \underset{x}{\text{min }} L(x, \nu) = - f^{*}(-A^T \nu) - b^T \nu
\end{eqnarray*}
where $\nu $ is the dual variable, and $f^*$ is the convex conjugate of $f$. The dual is given by:
\begin{eqnarray*}
\underset{\nu}{\text{maximize}} & & g(\nu)
\end{eqnarray*}
with variable $\nu \in \mathbb{R}^m$. Assuming that the strong duality holds, the optimal valules of the primal and the dual are the same. Then the following relation holds:
\begin{eqnarray*}
x^* &=& \underset{x}{\text{argmin }} L(x, \nu),
\end{eqnarray*}
where $x^*$ and $y^*$ are the two optimal arguments for the primal and the dual problem.

The dual ascent method solves the dual problem using gradient ascent. Assuming that $g$ is differentiable, we can evaluate $\nabla g(\nu)$ with $\nabla g(\nu) = Ax^+ - b$, which is the residual of the equality constraint and where $x^+ = \text{argmin}_x L(x, \nu)$. The dual ascent method is given by this iteration:
\begin{eqnarray*}
x^{k+1} &:=& \underset{x}{\text{argmin }} L(x, \nu^k) \\
\nu^{k+1} &:=& \nu^k + \alpha^k (A x^{k+1} - b),
\end{eqnarray*}
where $\alpha^k > 0$ is a step size, and the superscript is the iteration counter. We notice that this method is called dual ascent because with appropriate choice of $\alpha^k$, the dual function increases in each step, i.e. $g(\nu^k+1) > g(\nu^k)$. The dual ascent can also be used with non differentiable function under some modifications.
For an appropriate choice of $\alpha^k$ and under other conditions, we can make $x^k$ and $\nu^k$ converge to optimal primal and dual points. However, there is many example where the dual ascent method cannot be used.
The dual ascent method is very interesting because it can lead to a decentralized algorithm, meaning that the problem can be split into different peaces, which can be sold in parallel. Then for a separable function $f$, we get:
\begin{eqnarray*}
f(x) &=& \sum\limits_{i=1}^N f_i(x_i)
\end{eqnarray*}
where $x = (x_1,...,x_N)$ and the variable $x_i \in \mathbb{R}^{n_i}$ are subvectors of $x$. Then we partition the $A$ matrix so that we have:
\begin{eqnarray*}
A &=& [A_1 ... A_N] \\
Ax &=& \sum\limits_{i=1}^N A_ix_i
\end{eqnarray*}
Then the Lagrangian is written as:
\begin{eqnarray*}
L(x, \nu) = \sum\limits_{i=1}^N L_i(x_i, \nu) = \sum\limits_{i=1}^N (f_i(x_i) + \nu^TA_ix_i - (1/N)\nu^Tb)
\end{eqnarray*}
Then the dual ascent algorithm is given by:
\begin{eqnarray*}
x_i^{k+1} &:=& \underset{x_i}{\text{argmin }} L_i(x_i, \nu^k)\\
\nu^{k+1} &:=& \nu^k + \alpha^k(Ax^{k+1} - b)
\end{eqnarray*}
We notice that the $x$-minimization can be carried out independently, in parallel, for each $i=1,...,N$

\subsection{Method of Multipliers}
	\label{Method of Multipliers}
	
	The method of multipliers consists in augmenting the convex optimization problem \ref{Dual_ascent_pb}. We consider now:
\begin{eqnarray}
\label{M_M_pb}
\underset{x}{\text{minimize}} & & f(x) +(\rho/2)||Ax - b||_2^2 \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}

\subsection{ADMM}
	\label{ADMM}
	
	eizuhdiuzehdioza

 \bibliographystyle{unsrt}
 \bibliography{Bibliographie}

\clearpage

\end{document}
