\itshape\documentclass{article}

\usepackage[latin1]{inputenc}    
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage[toc,page]{appendix} 

\usepackage{wrapfig}
\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}

\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mdwlist}
\usepackage{booktabs} 

\usepackage{fullpage}

\begin{document}

\title{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}       
\author{Jack Reilly\and Boris Prodhomme\and Johann Grauzam\\ }       
\date{\today}         
\maketitle

\begin{abstract}

	ADMM \cite{ref1}
	
\end{abstract}

\section{Literature review}
 \label{Literature review}
 
	liyhgihgoih

\section{Different software frameworks}
 \label{Different software frameworks}
 
\subsection{Map-Reduce architecture}
	\label{Map-Reduce architecture} 
	
	MapReduce is a framework for processing highly distributable problems across huge datasets using a large number of computers, collectively referred to as a cluster. In this framework two main steps appear:

\begin{itemize}
\item ``Map'' step: the master computer divides in several sub-problems and send them to the other computers in the cluster. Once these worker computers have solved the sub-problem, they send back the solution to the master computer.

\item ``Reduce'' step: the master computer collects the results of all the sub-problems and combines them in a specific way to obtain a solution to the original main problem.

\end{itemize}

Provided each mapping operation is independent of the others, all maps can be performed in parallel. 	


\subsection{Hadoop}
	\label{Hadoop}
	
	Hadoop is a free Java framework that supports distributed applications.  It enables applications to work with thousands of computational independent computers and petabytes of data. A complete MapReduce algorithm can be used in this framework.
	
\subsection{Spark}
	\label{Spark}

	Spark is a cluster computing framework built on top of Mesos. As well as Hadoop, it supports distributed applications. The language used is Scala. 
	Spark's programming model is based on two constructs: parallel loops over ``distributed datasets'', and a limited set of types of shared variables that can be accessed from tasks running on different machines. This is the main advantage compared to Hadoop and the reason why we want to use this framework. Thanks to this architecture, we will be able to compute big calculations only once, and then the results will be shared with all the relevant computers. 


\section{Alternating Direction Method of Multipliers (ADMM)}
	\label{Alternating Direction Method of Multipliers (ADMM)}
	
\subsection{Dual Ascent}
	\label{Dual Ascent}
	
	Let consider the following convex optimization problem:
\begin{eqnarray}
\label{Dual_ascent_pb}
\underset{x}{\text{minimize}} & & f(x) \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}
with variables $x \in \mathbb{R}^n$, where $A \in \mathbb{R}^{m \times n}$ and $ f : \mathbb{R}^n \to \mathbb{R}$ is convex. 
The Lagrangian of problem \ref{Dual_ascent_pb} is:
\begin{eqnarray*}
\label{Dual_ascent_Lag}
L(x,\nu) = f(x) + \nu^T (b - Ax)
\end{eqnarray*}
and the dual function is:
\begin{eqnarray*}
g(\nu) = \underset{x}{\text{min }} L(x, \nu) = - f^{*}(-A^T \nu) - b^T \nu
\end{eqnarray*}
where $\nu $ is the dual variable, and $f^*$ is the convex conjugate of $f$. The dual is given by:
\begin{eqnarray*}
\underset{\nu}{\text{maximize}} & & g(\nu)
\end{eqnarray*}
with variable $\nu \in \mathbb{R}^m$. Assuming that the strong duality holds, the optimal valules of the primal and the dual are the same. Then the following relation holds:
\begin{eqnarray*}
x^* &=& \underset{x}{\text{argmin }} L(x, \nu),
\end{eqnarray*}
where $x^*$ and $y^*$ are the two optimal arguments for the primal and the dual problem.

The dual ascent method solves the dual problem using gradient ascent. Assuming that $g$ is differentiable, we can evaluate $\nabla g(\nu)$ with $\nabla g(\nu) = Ax^+ - b$, which is the residual of the equality constraint and where $x^+ = \text{argmin}_x L(x, \nu)$. The dual ascent method is given by this iteration:
\begin{eqnarray*}
x^{k+1} &:=& \underset{x}{\text{argmin }} L(x, \nu^k) \\
\nu^{k+1} &:=& \nu^k + \alpha^k (A x^{k+1} - b),
\end{eqnarray*}
where $\alpha^k > 0$ is a step size, and the superscript is the iteration counter. We notice that this method is called dual ascent because with appropriate choice of $\alpha^k$, the dual function increases in each step, i.e. $g(\nu^k+1) > g(\nu^k)$. The dual ascent can also be used with non differentiable function under some modifications.
For an appropriate choice of $\alpha^k$ and under other conditions, we can make $x^k$ and $\nu^k$ converge to optimal primal and dual points. However, there is many example where the dual ascent method cannot be used.
The dual ascent method is very interesting because it can lead to a decentralized algorithm, meaning that the problem can be split into different peaces, which can be sold in parallel. Then for a separable function $f$, we get:
\begin{eqnarray*}
f(x) &=& \sum\limits_{i=1}^N f_i(x_i)
\end{eqnarray*}
where $x = (x_1,...,x_N)$ and the variable $x_i \in \mathbb{R}^{n_i}$ are subvectors of $x$. Then we partition the $A$ matrix so that we have:
\begin{eqnarray*}
A &=& [A_1 ... A_N] \\
Ax &=& \sum\limits_{i=1}^N A_ix_i
\end{eqnarray*}
Then the Lagrangian is written as:
\begin{eqnarray*}
L(x, \nu) = \sum\limits_{i=1}^N L_i(x_i, \nu) = \sum\limits_{i=1}^N (f_i(x_i) + \nu^TA_ix_i - (1/N)\nu^Tb)
\end{eqnarray*}
Then the dual ascent algorithm is given by:
\begin{eqnarray*}
x_i^{k+1} &:=& \underset{x_i}{\text{argmin }} L_i(x_i, \nu^k)\\
\nu^{k+1} &:=& \nu^k + \alpha^k(Ax^{k+1} - b)
\end{eqnarray*}
We notice that the $x$-minimization can be carried out independently, in parallel, for each $i=1,...,N$

\subsection{Method of Multipliers}
	\label{Method of Multipliers}
	
	The method of multipliers consists in augmenting the convex optimization problem \ref{Dual_ascent_pb}. We consider now:
\begin{eqnarray}
\label{M_M_pb}
\underset{x}{\text{minimize}} & & f(x) +(\rho/2)||Ax - b||_2^2 \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}
Where $\rho > 0$ is called the penalty parameter. This is an equivalent problem because the equality constraint imposes to have $||Ax - b|| = 0$. Then the augmented Lagrangian becomes:
\begin{eqnarray*}
L_{rho}(x,\nu) = f(x) + \nu^T(Ax - b) + (\rho/2)||Ax - b||_2^2
\end{eqnarray*}
The augmented methods are usefull to make more robust the dual ascent method for example, and to evoid assumption as strict convexity or finitness of $f$. Then applying the dual ascent method to this new problem, we obtain the following algorithm:
\begin{eqnarray}
\label{M_M_alg}
x^{k+1} &:=& \underset{x}{\text{argmin }} L_{\rho}(x, \nu^k) \\
\nu^{k+1} &:=& \nu^k + \rho (A x^{k+1} - b),
\end{eqnarray}
This is known as the method of multipliers. This method converges under far more general conditions than dual ascent, including cases when $f$ takes on the value $+ \infty$ or is not strictly convex. 
The improved convergence properties reached thanks to the method of multipliers has a cost. Indeed we notice now that even if $f$ is separable, the augmented Lagrangian $L_{rho}$ is not separable anymore with the basic algorithm given in \ref{M_M_alg}. Then we cannot use decomposition anymore. This is one the reason why the ADMM was created.


\subsection{ADMM}
	\label{ADMM}
	
	The dual ascent method and the method of multipliers are both really usefull as described above. ADMM is an algorithm that tries to gather advantages of these two method, in minimizing the cost due to this combination. The problem treated will be under the following shape:
\begin{eqnarray}
\label{ADMM_pb}
\underset{x,z}{\text{minimize}} & & f(x) + g(z) \\
\text{subject to} & & Ax + Bz = c, \nonumber
\end{eqnarray}	
with variables $x \in \mathbb{R}^n$ and $z \in \mathbb{R}^m$, where $A \in \mathbb{R}^{p \times n}$, $B \in \mathbb{R}^{p \times m}$, and $c \in \mathbb{R}^{p}$.

 \bibliographystyle{unsrt}
 \bibliography{Bibliographie}

\clearpage

\end{document}
