\documentclass{article}

\usepackage[latin1]{inputenc}    
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage[toc,page]{appendix} 

\usepackage{wrapfig}
\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}

\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mdwlist}
\usepackage{booktabs} 

\usepackage{fullpage}

\begin{document}

\title{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}       
\author{Reilly Jack\and Prodhomme Boris\and Grauzam Johann\\ }       
\date{\today}         
\maketitle

\begin{abstract}

	ADMM \cite{ref1}
	
\end{abstract}

\section{Literature review}
 \label{Literature review}
 
	liyhgihgoih

\section{Different software frameworks}
 \label{Different software frameworks}

\subsection{Apache Hadoop}
	\label{Apache Hadoop}
	
	lrjfzjiozjf
	
\subsection{Mesos}
	\label{Mesos}
	
	lshfcizufhoizauh	
	
\subsection{Spark}
	\label{Spark}
	
	zdfjzpofjz


\section{Alternating Direction Method of Multipliers (ADMM)}
	\label{Alternating Direction Method of Multipliers (ADMM)}
	
\subsection{Dual Ascent}
	\label{Dual Ascent}
	
	Let consider the following convex optimization problem:
\begin{eqnarray}
\label{Dual_ascent_pb}
\underset{x}{\text{minimize}} & & f(x) \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}
with variables $x \in \mathbb{R}^n$, where $A \in \mathbb{R}^{m \times n}$ and $ f : \mathbb{R}^n \to \mathbb{R}$ is convex. 
The Lagrangian of problem \ref{Dual_ascent_pb} is:
\begin{eqnarray*}
\label{Dual_ascent_Lag}
L(x,\nu) = f(x) + \nu^T (b - Ax)
\end{eqnarray*}
and the dual function is:
\begin{eqnarray*}
g(\nu) = \underset{x}{\text{min }} L(x, \nu) = - f^{*}(-A^T \nu) - b^T \nu
\end{eqnarray*}
where $\nu $ is the dual variable, and $f^*$ is the convex conjugate of $f$. The dual is given by:
\begin{eqnarray*}
\underset{\nu}{\text{maximize}} & & g(\nu)
\end{eqnarray*}
with variable $\nu \in \mathbb{R}^m$. Assuming that the strong duality holds, the optimal valules of the primal and the dual are the same. Then the following relation holds:
\begin{eqnarray*}
x^* &=& \underset{x}{\text{argmin }} L(x, \nu),
\end{eqnarray*}
where $x^*$ and $y^*$ are the two optimal arguments for the primal and the dual problem.

The dual ascent method solves the dual problem using gradient ascent. Assuming that $g$ is differentiable, we can evaluate $\nabla g(\nu)$ with $\nabla g(\nu) = Ax^+ - b$, which is the residual of the equality constraint and where $x^+ = \text{argmin}_x L(x, \nu)$. The dual ascent method is given by this iteration:
\begin{eqnarray*}
x^{k+1} &:=& \underset{x}{\text{argmin }} L(x, \nu^k) \\
\nu^{k+1} &:=& \nu^k + \alpha^k (A x^{k+1} - b),
\end{eqnarray*}
where $\alpha^k > 0$ is a step size, and the superscript is the iteration counter. We notice that this method is called dual ascent because with appropriate choice of $\alpha^k$, the dual function increases in each step, i.e. $g(\nu^k+1) > g(\nu^k)$. The dual ascent can also be used with non differentiable function under some modifications.
For an appropriate choice of $\alpha^k$ and under other conditions, we can make $x^k$ and $\nu^k$ converge to optimal primal and dual points. However, there is many example where the dual ascent method cannot be used.
The dual ascent method is very interesting because it can lead to a decentralized algorithm, meaning that the problem can be split into different peaces, which can be sold in parallel. Then for a separable function $f$, we get:
\begin{eqnarray*}
f(x) &=& \sum\limits_{i=1}^N f_i(x_i)
\end{eqnarray*}
where $x = (x_1,...,x_N)$ and the variable $x_i \in \mathbb{R}^{n_i}$ are subvectors of $x$. Then we partition the $A$ matrix so that we have:
\begin{eqnarray*}
A &=& [A_1 ... A_N] \\
Ax &=& \sum\limits_{i=1}^N A_ix_i
\end{eqnarray*}
Then the Lagrangian is written as:
\begin{eqnarray*}
L(x, \nu) = \sum\limits_{i=1}^N L_i(x_i, \nu) = \sum\limits_{i=1}^N (f_i(x_i) + \nu^TA_ix_i - (1/N)\nu^Tb)
\end{eqnarray*}
Then the dual ascent algorithm is given by:
\begin{eqnarray*}
x_i^{k+1} &:=& \underset{x_i}{\text{argmin }} L_i(x_i, \nu^k)\\
\nu^{k+1} &:=& \nu^k + \alpha^k(Ax^{k+1} - b)
\end{eqnarray*}
We notice that the $x$-minimization can be carried out independently, in parallel, for each $i=1,...,N$

\subsection{Method of Multipliers}
	\label{Method of Multipliers}
	
	The method of multipliers consists in augmenting the convex optimization problem \ref{Dual_ascent_pb}. We consider now:
\begin{eqnarray}
\label{M_M_pb}
\underset{x}{\text{minimize}} & & f(x) +(\rho/2)||Ax - b||_2^2 \\
\text{subject to} & & Ax = b, \nonumber
\end{eqnarray}
Where $\rho > 0$ is called the penalty parameter. This is an equivalent problem because the equality constraint imposes to have $||Ax - b|| = 0$. Then the augmented Lagrangian becomes:
\begin{eqnarray*}
L_{rho}(x,\nu) = f(x) + \nu^T(Ax - b) + (\rho/2)||Ax - b||_2^2
\end{eqnarray*}
The augmented methods are usefull to make more robust the dual ascent method for example, and to evoid assumption as strict convexity or finitness of $f$. Then applying the dual ascent method to this new problem, we obtain the following algorithm:
\begin{eqnarray}
\label{M_M_alg}
x^{k+1} &:=& \underset{x}{\text{argmin }} L_{\rho}(x, \nu^k) \\
\nu^{k+1} &:=& \nu^k + \rho (A x^{k+1} - b),
\end{eqnarray}
This is known as the method of multipliers. This method converges under far more general conditions than dual ascent, including cases when $f$ takes on the value $+ \infty$ or is not strictly convex. 
The improved convergence properties reached thanks to the method of multipliers has a cost. Indeed we notice now that even if $f$ is separable, the augmented Lagrangian $L_{rho}$ is not separable anymore with the basic algorithm given in \ref{M_M_alg}. Then we cannot use decomposition anymore. This is one the reason why the ADMM was created.


\subsection{ADMM}
	\label{ADMM}
	
	The dual ascent method and the method of multipliers are both really usefull as described above. ADMM is an algorithm that tries to gather advantages of these two method, in minimizing the cost due to this combination. The problem treated will be under the following shape:
\begin{eqnarray}
\label{ADMM_pb}
\underset{x,z}{\text{minimize}} & & f(x) + g(z) \\
\text{subject to} & & Ax + Bz = c, \nonumber
\end{eqnarray}	
with variables $x \in \mathbb{R}^n$ and $z \in \mathbb{R}^m$, where $A \in \mathbb{R}^{p \times n}$, $B \in \mathbb{R}^{p \times m}$, and $c \in \mathbb{R}^{p}$.

 \bibliographystyle{unsrt}
 \bibliography{Bibliographie}

\clearpage

\end{document}
